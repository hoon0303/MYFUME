{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T10:26:06.534035Z","iopub.status.busy":"2024-09-11T10:26:06.533721Z","iopub.status.idle":"2024-09-11T10:26:09.084223Z","shell.execute_reply":"2024-09-11T10:26:09.083376Z","shell.execute_reply.started":"2024-09-11T10:26:06.533996Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, precision_score, recall_score\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T10:26:09.085829Z","iopub.status.busy":"2024-09-11T10:26:09.085384Z","iopub.status.idle":"2024-09-11T10:26:09.142754Z","shell.execute_reply":"2024-09-11T10:26:09.141662Z","shell.execute_reply.started":"2024-09-11T10:26:09.085795Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T10:26:09.144538Z","iopub.status.busy":"2024-09-11T10:26:09.144212Z","iopub.status.idle":"2024-09-11T10:26:09.152022Z","shell.execute_reply":"2024-09-11T10:26:09.150950Z","shell.execute_reply.started":"2024-09-11T10:26:09.144505Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.X.iloc[idx].values, dtype=torch.float32), torch.tensor(self.y.iloc[idx], dtype=torch.float32)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T10:26:09.154937Z","iopub.status.busy":"2024-09-11T10:26:09.154523Z","iopub.status.idle":"2024-09-11T10:26:09.168053Z","shell.execute_reply":"2024-09-11T10:26:09.167085Z","shell.execute_reply.started":"2024-09-11T10:26:09.154893Z"},"trusted":true},"outputs":[],"source":["class DeepFM(nn.Module):\n","    def __init__(self, sparse_input_dims, dense_input_dim, embedding_dim, dnn_hidden_units):\n","        super(DeepFM, self).__init__()\n","        \n","        # Embedding layers for sparse features\n","        self.embeddings = nn.ModuleList([nn.Embedding(input_dim, embedding_dim) for input_dim in sparse_input_dims])\n","        \n","        # Linear part\n","        self.linear = nn.ModuleList([nn.Embedding(input_dim, 1) for input_dim in sparse_input_dims])\n","        \n","        # DNN part\n","        dnn_input_dim = embedding_dim * len(sparse_input_dims) + dense_input_dim\n","        layers = []\n","        for i in range(len(dnn_hidden_units)):\n","            if i == 0:\n","                layers.append(nn.Linear(dnn_input_dim, dnn_hidden_units[i]))\n","            else:\n","                layers.append(nn.Linear(dnn_hidden_units[i-1], dnn_hidden_units[i]))\n","            layers.append(nn.ReLU())\n","        self.dnn = nn.Sequential(*layers)\n","        self.dnn_output = nn.Linear(dnn_hidden_units[-1], 1)\n","        \n","    def forward(self, x_sparse, x_dense):\n","        # Linear part\n","        linear_logit = sum([self.linear[i](x_sparse[:, i]) for i in range(x_sparse.shape[1])]).squeeze(1)\n","        \n","        # Embedding and interaction part\n","        embeddings = [self.embeddings[i](x_sparse[:, i]) for i in range(x_sparse.shape[1])]\n","        fm_logit = sum([torch.sum(embed_i * embed_j, dim=1, keepdim=True) \n","                        for i, embed_i in enumerate(embeddings)\n","                        for j, embed_j in enumerate(embeddings) if i < j]).squeeze(1)\n","        \n","        # DNN part\n","        dnn_input = torch.cat(embeddings + [x_dense], dim=1)\n","        dnn_logit = self.dnn(dnn_input)\n","        dnn_logit = self.dnn_output(dnn_logit).squeeze(1)\n","        \n","        # Final output\n","        logit = linear_logit + fm_logit + dnn_logit\n","        output = torch.sigmoid(logit)\n","        return output\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T10:26:09.172301Z","iopub.status.busy":"2024-09-11T10:26:09.171952Z","iopub.status.idle":"2024-09-11T10:26:09.181418Z","shell.execute_reply":"2024-09-11T10:26:09.180424Z","shell.execute_reply.started":"2024-09-11T10:26:09.172269Z"},"trusted":true},"outputs":[],"source":["def train_model(X_train, y_train, sparse_input_dims, dense_input_dim, embedding_dim, dnn_hidden_units, epochs, learning_rate):\n","    model = DeepFM(sparse_input_dims, dense_input_dim, embedding_dim, dnn_hidden_units).to(device)\n","    criterion = nn.BCELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        X_train, y_train = X_train.to(device), y_train.to(device)\n","        X_sparse = X_train[:, :len(sparse_input_dims)].long()\n","        X_dense = X_train[:, len(sparse_input_dims):]\n","        optimizer.zero_grad()\n","        outputs = model(X_sparse, X_dense)\n","        loss = criterion(outputs, y_train)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        predicted = (outputs > 0.5).float()\n","        correct = (predicted == y_train).sum().item()\n","        accuracy = correct / y_train.size(0)\n","\n","        if (epoch + 1) % 100 == 0:\n","            print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}\")\n","            \n","    return model\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T10:26:09.183082Z","iopub.status.busy":"2024-09-11T10:26:09.182687Z","iopub.status.idle":"2024-09-11T10:26:09.194417Z","shell.execute_reply":"2024-09-11T10:26:09.193636Z","shell.execute_reply.started":"2024-09-11T10:26:09.183040Z"},"trusted":true},"outputs":[],"source":["def evaluate_model(model, X_test, y_test, sparse_input_dims):\n","    model.eval()\n","    y_true = []\n","    y_pred = []\n","    with torch.no_grad():\n","        X_test, y_test = X_test.to(device), y_test.to(device)\n","        X_sparse = X_test[:, :len(sparse_input_dims)].long()\n","        X_dense = X_test[:, len(sparse_input_dims):]\n","        outputs = model(X_sparse, X_dense)\n","        y_true.extend(y_test.cpu().numpy())\n","        y_pred.extend(outputs.cpu().numpy())\n","    \n","    y_pred_labels = np.where(np.array(y_pred) > 0.5, 1, 0)\n","    accuracy = accuracy_score(y_true, y_pred_labels)\n","    roc_auc = roc_auc_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred_labels)\n","    recall = recall_score(y_true, y_pred_labels)\n","    log_loss_value = log_loss(y_true, y_pred)\n","\n","    return accuracy, roc_auc, precision, recall, log_loss_value, y_true, y_pred"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T10:26:09.197860Z","iopub.status.busy":"2024-09-11T10:26:09.197568Z","iopub.status.idle":"2024-09-11T10:26:09.208128Z","shell.execute_reply":"2024-09-11T10:26:09.207135Z","shell.execute_reply.started":"2024-09-11T10:26:09.197830Z"},"trusted":true},"outputs":[],"source":["def load_data(item_path, review_path):\n","    item_data = pd.read_csv(item_path)\n","    review_data = pd.read_csv(review_path)\n","\n","    data_merge = pd.merge(review_data, item_data, on=\"N_id\")\n","    data_merge['Target'] = np.where(data_merge['Target'] > 3, 1, 0)\n","\n","    User_category = data_merge.pivot_table(\"Target\", index=\"User\", columns=\"Smell\", aggfunc=\"mean\")\n","    User_category_matrix = User_category.fillna(0)\n","\n","    data_merge = pd.merge(data_merge, User_category_matrix, on=\"User\")\n","\n","    sparse_features = ['Company', 'Smell', 'Gender', 'Year']\n","    dense_features = User_category_matrix.columns.tolist()\n","    sparse_input_dims = []\n","    for feat in sparse_features:\n","        lbe = LabelEncoder()\n","        data_merge[feat] = lbe.fit_transform(data_merge[feat])\n","        max_val = data_merge[feat].max()\n","        print(f\"{feat}: {len(lbe.classes_)} classes, max value: {max_val}\")\n","        sparse_input_dims.append(len(lbe.classes_) + 1)\n","        \n","    mms = MinMaxScaler()\n","    data_merge[dense_features] = mms.fit_transform(data_merge[dense_features])\n","\n","    x = data_merge[sparse_features + dense_features]\n","    y = data_merge['Target']\n","    \n","    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=52, shuffle=True, stratify=y)\n","    \n","    return x_train, x_test, y_train, y_test, sparse_features, dense_features, sparse_input_dims\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T10:26:09.209385Z","iopub.status.busy":"2024-09-11T10:26:09.209086Z","iopub.status.idle":"2024-09-11T10:27:14.157580Z","shell.execute_reply":"2024-09-11T10:27:14.156502Z","shell.execute_reply.started":"2024-09-11T10:26:09.209354Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Company: 2906 classes, max value: 2905\n","Smell: 32 classes, max value: 31\n","Gender: 4 classes, max value: 3\n","Year: 166 classes, max value: 165\n","Sparse input dimensions: [2907, 33, 5, 167]\n","Epoch [100/1000], Loss: 1.5008, Accuracy: 0.7708\n","Epoch [200/1000], Loss: 0.5442, Accuracy: 0.8097\n","Epoch [300/1000], Loss: 0.3774, Accuracy: 0.8523\n","Epoch [400/1000], Loss: 0.3359, Accuracy: 0.8673\n","Epoch [500/1000], Loss: 0.3103, Accuracy: 0.8758\n","Epoch [600/1000], Loss: 0.2927, Accuracy: 0.8830\n","Epoch [700/1000], Loss: 0.2767, Accuracy: 0.8879\n","Epoch [800/1000], Loss: 0.2652, Accuracy: 0.8920\n","Epoch [900/1000], Loss: 0.2564, Accuracy: 0.8956\n","Epoch [1000/1000], Loss: 0.2479, Accuracy: 0.8985\n","Final Evaluation - Accuracy: 0.8817889153947703, ROC-AUC: 0.8767623655092128, Log Loss: 0.2931595459306287\n"]}],"source":["item_path = 'data/item.csv'\n","review_path = 'data/review.csv'\n","x_train, x_test, y_train, y_test, sparse_features, dense_features, sparse_input_dims = load_data(item_path, review_path)\n","\n","embedding_dim = 8\n","dnn_hidden_units = [256, 128]\n","epochs = 1000\n","learning_rate = 0.001\n","\n","dense_input_dim = len(dense_features)\n","\n","print(f\"Sparse input dimensions: {sparse_input_dims}\")\n","\n","# Convert the train and test data to tensors\n","X_train_tensor = torch.tensor(x_train.values, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n","X_test_tensor = torch.tensor(x_test.values, dtype=torch.float32)\n","y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n","\n","# Train the model\n","model = train_model(X_train_tensor, y_train_tensor, sparse_input_dims, dense_input_dim, embedding_dim, dnn_hidden_units, epochs, learning_rate)\n","\n","# Evaluate the model\n","accuracy, roc_auc, precision, recall, log_loss_value, y_true, y_pred = evaluate_model(model, X_test_tensor, y_test_tensor, sparse_input_dims)\n","\n","print(f\"Final Evaluation - Accuracy: {accuracy}, ROC-AUC: {roc_auc}, Log Loss: {log_loss_value}\")\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5679761,"sourceId":9366239,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
